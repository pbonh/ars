1. Goals

<!--
Explain the main objective of your prompt or query. 
- What problem are you trying to solve?
- What kind of output or insight do you need?
- Are you asking for a list, a summary, an analysis, or a plan of action?

Example:
"Analyze the provided user feedback and suggest three ways to improve product usability."
-->[Replace this text with your specific goals or objectives.]

2. Return Format

<!--
Define exactly how you want the LLM to present its answer. 
- Should it be a numbered list, bullet points, a short paragraph, or code snippet?
- Are there any stylistic guidelines to follow (e.g., no first-person language)?
- Is there a specific data format like JSON or XML?

Example:
"Please return your answer as a JSON object with fields 'summary' and 'recommendations'."
-->[Replace this text with instructions for the desired format of the response.]

3. Warnings

<!--
List any important caveats, constraints, or sensitive information. 
- Do you need to remind the LLM about confidentiality or disclaimers?
- Are there any topics or details to avoid?
- Are there any factual or ethical considerations?

Example:
"Do not share any personal user data. Avoid speculation about user identities."
-->[Replace this text with important warnings or guidelines for the LLM.]

4. Context Dump

<!--
Provide all the background information that the LLM needs to generate its response. 
- This can include prior conversation transcripts, relevant facts, or any additional resources.
- More context generally helps the LLM produce a more accurate and relevant answer.

Example:
"Userâ€™s previous conversation logs, relevant product requirements, existing code snippets, design guidelines, etc."
-->[Replace this text with your detailed context or references.]
